{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5433f8",
   "metadata": {},
   "source": [
    "# Comparisons of Different BPE Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e3558",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e247f60",
   "metadata": {},
   "source": [
    "## BPE From tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb62b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d3ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11633, 262, 2068, 7586, 21831, 4391, 625, 262, 16931, 6844, 30]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tik_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Did the quick brown fox jump over the lazy dogs?\"\n",
    "\n",
    "integers = tik_tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4db3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did the quick brown fox jump over the lazy dogs?\n"
     ]
    }
   ],
   "source": [
    "strings = tik_tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9e9b511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(tik_tokenizer.n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fe27e",
   "metadata": {},
   "source": [
    "## BPE Implementation of GPT-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e775a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_gpt2_bpe import get_encoder, download_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b2ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching encoder.json: 1.04Mit [00:20, 51.5kit/s]                                                   \n",
      "Fetching vocab.bpe: 457kit [00:04, 93.1kit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "download_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4803d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_tokenizer = get_encoder(model_name=\"gpt2_model\", models_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee36e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11633, 262, 2068, 7586, 21831, 4391, 625, 262, 16931, 6844, 30]\n"
     ]
    }
   ],
   "source": [
    "integers = oai_tokenizer.encode(text)\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3079b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did the quick brown fox jump over the lazy dogs?\n"
     ]
    }
   ],
   "source": [
    "strings = oai_tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd64b17",
   "metadata": {},
   "source": [
    "## BPE via HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3954aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bac/code/nbs/LLMs-from-scratch/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.51.3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02004f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "hf_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f55e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11633, 262, 2068, 7586, 21831, 4391, 625, 262, 16931, 6844, 30]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer(strings)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65df0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "hf_tokenizer_fast = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093933ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11633, 262, 2068, 7586, 21831, 4391, 625, 262, 16931, 6844, 30]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer_fast(strings)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4921a5",
   "metadata": {},
   "source": [
    "## Sebastian's Local BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f18f3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, io, nbformat, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_notebook():\n",
    "    def import_definitions_from_notebook(fullname, names):\n",
    "        current_dir = os.getcwd()\n",
    "        path = os.path.join(current_dir, \"..\", \"01b-bpe-from-scratch\", fullname + \".ipynb\")\n",
    "        path = os.path.normpath(path)\n",
    "        \n",
    "        # Load the NB\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Notebook not found at --> {path}\")\n",
    "        \n",
    "        with io.open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "            \n",
    "        # Create module to store the imported funcs and classes\n",
    "        mod = types.ModuleType(fullname)\n",
    "        sys.modules[fullname] = mod\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
