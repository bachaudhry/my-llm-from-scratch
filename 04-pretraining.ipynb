{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4f2754",
   "metadata": {},
   "source": [
    "# **Pretraining an LLM on Unlabeled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543b63a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.2.5\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights since earlier models were trained in TensorFlow\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbfa8a",
   "metadata": {},
   "source": [
    "This notebook covers the following topics in addition to covering a basic training loop for an introduction to model evaluations during LLM pretraining.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86298966",
   "metadata": {},
   "source": [
    "## **1. Evaluating Generative Text Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a74d0",
   "metadata": {},
   "source": [
    "Let's begin by setting up the LLM's configuration from previous notebooks. We will be retaining the original context length since we have access to a reasonable consumer grade GPU which should easily handle `context_length: 1024`. This is the same configuration as the original GPT-2 model with 124 million parameters.\n",
    "\n",
    "`text_to_token_ids()` and `token_ids_to_text()` are functions which facilitate the conversion between text and token representations. Additionally, it is important to note that modern LLMs **do not** use a dropout rate as well as bias vectors. The dropout rate below reflects the settings used to train the original GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2d2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.components import GPTModel\n",
    "\n",
    "# GPT configuration from previos NBs\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Retaining original context length\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate \n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # Dropout disabled during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4077f",
   "metadata": {},
   "source": [
    "`NOTE` Experiment with context lengths and embedding dimensions to generate longer sequences from larger text files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b01a17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Time and tide wait Sturgeon prenatalsql unseEF behavioral Python averagexxx predictor\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from utils.components import generate_text_simple\n",
    "\n",
    "# Pipeline functions\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Removing batch dim\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Time and tide wait\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11161b8",
   "metadata": {},
   "source": [
    "The generated text is gibberish since the model hasn't been trained yet. We will also be evaluating the quality of text generation in sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b4d05",
   "metadata": {},
   "source": [
    "### **1.1 Calculating The Text Generation Loss i.e. Cross-Entropy and Perplexity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd34b0",
   "metadata": {},
   "source": [
    "For demonstration purposes, we will create two inputs of three tokens each and will then compute vectors containing the probability scores corresponding to each token in the vocabulary. The index of the highest probability score in each vector represents the most likely next token ID which is then returned to generate the required text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ffbc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ddb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "    \n",
    "probs = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probs.shape) # Shape ==> (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d42e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[24851],\n",
      "         [  406],\n",
      "         [40115]],\n",
      "\n",
      "        [[29716],\n",
      "         [40825],\n",
      "         [19647]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df1d1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: etti L HO\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e053b",
   "metadata": {},
   "source": [
    "The output tokens don't match the target tokens we created above - as expected. But we also want to know how far the generated tokens are from the correct predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a35293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.3173e-06, 2.1993e-05, 1.0362e-05])\n",
      "Text 1: tensor([1.2699e-05, 2.9482e-05, 6.5255e-06])\n"
     ]
    }
   ],
   "source": [
    "# Token probabilities corresponding to the target indices\n",
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probs_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6ae5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.3529, -10.7248, -11.4774, -11.2740, -10.4317, -11.9398])\n"
     ]
    }
   ],
   "source": [
    "# Compute log of all token probabilities\n",
    "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c144d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.3668)\n"
     ]
    }
   ],
   "source": [
    "# Computing the average log probability of each token\n",
    "avg_log_probs = torch.mean(log_probs)\n",
    "print(avg_log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ff640",
   "metadata": {},
   "source": [
    ">- The goal is to make this average log probability as large as possible by optimizing the model weights\n",
    ">- Due to the log, the largest possible value is 0, and we are currently far away from 0\n",
    ">- In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the *negative* average log-probability value.\n",
    "\n",
    "**`CROSS ENTROPY`** This measures the difference between two probability distributions - which in this case are the true distributions of the labels and the predicted distributions from the model i.e. the token probabilities generated by the LLM. PyTorch uses the cross-entropy function for discrete outcomes which _is similar to negative average log probability of the target tokens given the model's generated token probabilities_, thus making the two terms interchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9799e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3668)\n"
     ]
    }
   ],
   "source": [
    "# Minimize the negative average log-probability\n",
    "neg_avg_log_prob = avg_log_probs * -1\n",
    "print(neg_avg_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff311793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Prior to implementing cross entropy, we should check the shape of logits and targets\n",
    "# Logits shape --> (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ce95555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross-Entropy loss: tensor(11.3668)\n"
     ]
    }
   ],
   "source": [
    "# Flattening above tensors for cross entropy. Flattening is done by combining over the batch dimension\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "# Applying cross entropy loss\n",
    "# Previously we, applied the softmax function, selected probability scores corresponding to target ids and\n",
    "# computed the negative average log probabilities. Cross Entropy handles all of these steps.\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "\n",
    "# Printing shapes and cross entropy loss\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "print(\"Cross-Entropy loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3a0cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "torch.nn.functional.cross_entropy(\n",
      "    input: torch.Tensor,\n",
      "    target: torch.Tensor,\n",
      "    weight: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    size_average: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ignore_index: int = -\u001b[32m100\u001b[39m,\n",
      "    reduce: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    reduction: str = \u001b[33m'mean'\u001b[39m,\n",
      "    label_smoothing: float = \u001b[32m0.0\u001b[39m,\n",
      ") -> torch.Tensor\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Compute the cross entropy loss between input logits and target.\n",
      "\n",
      "See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
      "\n",
      "Args:\n",
      "    input (Tensor) : Predicted unnormalized logits;\n",
      "        see Shape section below for supported shapes.\n",
      "    target (Tensor) : Ground truth class indices or class probabilities;\n",
      "        see Shape section below for supported shapes.\n",
      "    weight (Tensor, optional): a manual rescaling weight given to each\n",
      "        class. If given, has to be a Tensor of size `C`\n",
      "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "        the losses are averaged over each loss element in the batch. Note that for\n",
      "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "        when reduce is ``False``. Default: ``True``\n",
      "    ignore_index (int, optional): Specifies a target value that is ignored\n",
      "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "        Default: -100\n",
      "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "        losses are averaged or summed over observations for each minibatch depending\n",
      "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
      "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "        ``'mean'``: the sum of the output will be divided by the number of\n",
      "        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "        become a mixture of the original ground truth and a uniform distribution as described in\n",
      "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "\n",
      "Shape:\n",
      "    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "      in the case of `K`-dimensional loss.\n",
      "    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n",
      "      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n",
      "\n",
      "    where:\n",
      "\n",
      "    .. math::\n",
      "        \\begin{aligned}\n",
      "            C ={} & \\text{number of classes} \\\\\n",
      "            N ={} & \\text{batch size} \\\\\n",
      "        \\end{aligned}\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # Example of target with class indices\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
      "    >>> loss = F.cross_entropy(input, target)\n",
      "    >>> loss.backward()\n",
      "    >>>\n",
      "    >>> # Example of target with class probabilities\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "    >>> loss = F.cross_entropy(input, target)\n",
      "    >>> loss.backward()\n",
      "\u001b[31mFile:\u001b[39m      ~/code/nbs/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/nn/functional.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557c90c",
   "metadata": {},
   "source": [
    "**`Perplexity`** This is a measure used in conjuction with cross entropy loss to evaluate the performance of models in tasks like language modeling. It can provide a more interpretable way to understand the uncertainty of a model in predicting the next sequence. Specifically, it measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset. Lower perplexity indcates that the model predictions are closed to the actual distribution.\n",
    "\n",
    "This measure is often considered to be more interpretable than the raw loss value because it signifies the effective vocabulary size that the model is _unsure_ of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d70dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(86402.1562)\n"
     ]
    }
   ],
   "source": [
    "# Calculating the perplexity \n",
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6110d4",
   "metadata": {},
   "source": [
    "### **1.2 Calculating Training and Validation Losses** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c97b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Loading sample training text.\n",
    "#file_path = \"data/the-law-bastiat.txt\"\n",
    "file_path = \"data/the-verdict.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57b0673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no  \n",
      "\n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# First and last99 chars\n",
    "print(text_data[:99], \"\\n\")\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2ea6491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters: \", total_characters)\n",
    "print(\"Tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37d7cc",
   "metadata": {},
   "source": [
    "Here, we will be training our model with training data presented in similarly sized chunks for simplicity and efficiency. In practice, it can also be beneficial to train an LLM with variable-length inputs to help it to better generalize across different types of inputs when it is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f534f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.components import create_dataloader_v1\n",
    "\n",
    "# Training / validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc5602c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running sanity check\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader!\")\n",
    "    \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81d18ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Checking shapes of train and val loaders.\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8526bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# Checking token sizes\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "    \n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90df534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the loss of a single batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# Calculate the loss over all batches sampled by a given data loader.\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce num of batches to match the total number of batches in the data loader\n",
    "        # in case values are exceeded.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else: \n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8668e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.003963894314236\n",
      "Validation loss: 11.044095039367676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "    \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031ffd2",
   "metadata": {},
   "source": [
    "## 2. Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb7a6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            # Additional eval step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        # Print sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context)\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "    \n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "        model.eval()\n",
    "        context_size = model.pos_emb.weight.shape[0]\n",
    "        encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "        with torch.no_grad():\n",
    "            token_ids = generate_text_simple(\n",
    "                model=model, idx=encoded,\n",
    "                max_new_tokens=50, context_size=context_size\n",
    "                )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "        model.train()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fe9a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear cache for repeat runs\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1b5a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 10.032, Val loss 10.127\n",
      "Epoch 1 (Step 000005): Train loss 8.172, Val loss 8.353\n",
      "Time and tide wait,,, the,                                             \n",
      "Epoch 2 (Step 000010): Train loss 6.796, Val loss 7.099\n",
      "Epoch 2 (Step 000015): Train loss 6.064, Val loss 6.640\n",
      "Time and tide wait, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the,, the, the, the, the, the, the, the,\n",
      "Epoch 3 (Step 000020): Train loss 5.668, Val loss 6.606\n",
      "Epoch 3 (Step 000025): Train loss 5.292, Val loss 6.571\n",
      "Time and tide wait thought it was his aburn had a he had a in the aI of theI of theI I had in theI. Gisburn, and I had a he had a in the of theI. Gisburn had theI\n",
      "Epoch 4 (Step 000030): Train loss 5.211, Val loss 6.418\n",
      "Epoch 4 (Step 000035): Train loss 4.470, Val loss 6.382\n",
      "Time and tide wait.                                                 \n",
      "Epoch 5 (Step 000040): Train loss 3.923, Val loss 6.297\n",
      "Time and tide wait to the                                                \n",
      "Epoch 6 (Step 000045): Train loss 3.522, Val loss 6.302\n",
      "Epoch 6 (Step 000050): Train loss 3.104, Val loss 6.257\n",
      "Time and tide wait.      \" to the donkey--as the. \"Oh, and I looked up, I had to see a smile behind his close the donkey, I had to me, the donkey.      \n",
      "Epoch 7 (Step 000055): Train loss 2.531, Val loss 6.275\n",
      "Epoch 7 (Step 000060): Train loss 2.008, Val loss 6.290\n",
      "Time and tide wait I had been up-rooms, as it--I had the the background of the house.\"       \"Oh, and he had the first, and he had the he had the donkey. \"strong.   \n",
      "Epoch 8 (Step 000065): Train loss 1.626, Val loss 6.311\n",
      "Epoch 8 (Step 000070): Train loss 1.362, Val loss 6.319\n",
      "Time and tide wait of the inevitable garlanded frame.  \"I turned to the donkey. \"I turned, the fact, the end of the display of his close grayish beard--as if he had the donkey.      \n",
      "Epoch 9 (Step 000075): Train loss 1.104, Val loss 6.297\n",
      "Epoch 9 (Step 000080): Train loss 0.746, Val loss 6.476\n",
      "Time and tide wait of the inevitable garlanded frame. Gisburn--as such--had not existed till nearly a year after Jack's resolve had been taken. It might be that he had married her--the quality of Jack's \"There were days when I\n",
      "Epoch 10 (Step 000085): Train loss 0.631, Val loss 6.576\n",
      "Time and tide wait I'd never touched a brush.\"  \"I told Mrs.  \"Once, and thought of anything else. \"I moved away, his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Training completed in 0.23 mins.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Time and tide wait\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time:.2f} mins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39b969a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    #plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fed1c",
   "metadata": {},
   "source": [
    "`NOTE` Experiment with augmenting the training function with\n",
    "- Warmup\n",
    "- Cosine Annealing\n",
    "- Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2fa96",
   "metadata": {},
   "source": [
    "## 3 . Decoding Strategies to Control Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae217a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Time and tide wait I'd never touched a brush.\"\n",
      "\n",
      "\"I told Mrs.\n",
      "\n",
      "\"Once, and thought of anything else.\n",
      "\"I moved away, his close grayish beard--as if he had the donkey. \"strongest,\" as his\n"
     ]
    }
   ],
   "source": [
    "# Shifting inference to CPU\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Time and tide wait\", tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c13f7",
   "metadata": {},
   "source": [
    "### 3.1 Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f52175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"there\": 0,\n",
    "    \"is\": 1,\n",
    "    \"for\": 2,\n",
    "    \"man\": 3,\n",
    "    \"no\": 4,\n",
    "    \"help\": 5,\n",
    "    \"ecstatic\": 6,\n",
    "    \"you\": 7,\n",
    "    \"inches\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v:k for k, v in vocab.items()}\n",
    "\n",
    "# As an example, for an input like \"In the grim darkness of the far future\" the LLM\n",
    "# may return the folowing logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, 7.25, 6.15, 6.82, -1.62, -1.89, 2.55, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item() \n",
    "\n",
    "# Next generated token is\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c434d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97002797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 x there\n",
      "1 x is\n",
      "481 x for\n",
      "159 x man\n",
      "325 x no\n",
      "0 x help\n",
      "0 x ecstatic\n",
      "1 x you\n",
      "2 x inches\n"
     ]
    }
   ],
   "source": [
    "# Sampling the next token 1000 times using the original softmax probabilities\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(42)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "        \n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5261dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5] # original, higher confidence, lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a875e5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distributions\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f\"Temperature = {T}\")\n",
    "    \n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507748c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x there\n",
      "0 x is\n",
      "984 x for\n",
      "0 x man\n",
      "16 x no\n",
      "0 x help\n",
      "0 x ecstatic\n",
      "0 x you\n",
      "0 x inches\n"
     ]
    }
   ],
   "source": [
    "# Scaling with temperature 0.1 - results in a sharper distribution\n",
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 x there\n",
      "59 x is\n",
      "224 x for\n",
      "185 x man\n",
      "198 x no\n",
      "32 x help\n",
      "24 x ecstatic\n",
      "96 x you\n",
      "55 x inches\n"
     ]
    }
   ],
   "source": [
    "# Scaling with temperature 5 - results in a more uniform distribution\n",
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9a457a",
   "metadata": {},
   "source": [
    "### 3.2 Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f16f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits:  tensor([7.2500, 6.8200, 6.1500])\n",
      "Top position:  tensor([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Higher temperature values increase diversity. To reduce the probability of generating gibberish we can use top-k sampling\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits: \", top_logits)\n",
    "print(\"Top position: \", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7522125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDocstring:\u001b[39m\n",
      "topk(input, k, dim=None, largest=True, sorted=True, *, out=None) -> (Tensor, LongTensor)\n",
      "\n",
      "Returns the :attr:`k` largest elements of the given :attr:`input` tensor along\n",
      "a given dimension.\n",
      "\n",
      "If :attr:`dim` is not given, the last dimension of the `input` is chosen.\n",
      "\n",
      "If :attr:`largest` is ``False`` then the `k` smallest elements are returned.\n",
      "\n",
      "A namedtuple of `(values, indices)` is returned with the `values` and\n",
      "`indices` of the largest `k` elements of each row of the `input` tensor in the\n",
      "given dimension `dim`.\n",
      "\n",
      "The boolean option :attr:`sorted` if ``True``, will make sure that the returned\n",
      "`k` elements are themselves sorted\n",
      "\n",
      ".. note::\n",
      "    When using `torch.topk`, the indices of tied elements are not guaranteed to be stable\n",
      "    and may vary across different invocations.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the input tensor.\n",
      "    k (int): the k in \"top-k\"\n",
      "    dim (int, optional): the dimension to sort along\n",
      "    largest (bool, optional): controls whether to return largest or\n",
      "           smallest elements\n",
      "    sorted (bool, optional): controls whether to return the elements\n",
      "           in sorted order\n",
      "\n",
      "Keyword args:\n",
      "    out (tuple, optional): the output tuple of (Tensor, LongTensor) that can be\n",
      "        optionally given to be used as output buffers\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> x = torch.arange(1., 6.)\n",
      "    >>> x\n",
      "    tensor([ 1.,  2.,  3.,  4.,  5.])\n",
      "    >>> torch.topk(x, 3)\n",
      "    torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))\n",
      "\u001b[31mType:\u001b[39m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.topk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e278627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  -inf,   -inf, 7.2500, 6.1500, 6.8200,   -inf,   -inf,   -inf,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition = next_token_logits < top_logits[-1],\n",
    "    input = torch.tensor(float(\"-inf\")),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9843bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.5042, 0.1678, 0.3280, 0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Alternative and more efficient implementation of the above cell\n",
    "new_logits = torch.full_like(\n",
    "    next_token_logits,\n",
    "    fill_value= -torch.inf\n",
    ")\n",
    "\n",
    "new_logits[top_pos] = next_token_logits[top_pos] # copy top-k values into the -inf tensor\n",
    "\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e12bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDocstring:\u001b[39m\n",
      "full_like(input, fill_value, \\*, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format) -> Tensor\n",
      "\n",
      "Returns a tensor with the same size as :attr:`input` filled with :attr:`fill_value`.\n",
      "``torch.full_like(input, fill_value)`` is equivalent to\n",
      "``torch.full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device)``.\n",
      "\n",
      "Args:\n",
      "    input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n",
      "    fill_value: the number to fill the output tensor with.\n",
      "\n",
      "Keyword args:\n",
      "    dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n",
      "        Default: if ``None``, defaults to the dtype of :attr:`input`.\n",
      "    layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n",
      "        Default: if ``None``, defaults to the layout of :attr:`input`.\n",
      "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "        Default: if ``None``, defaults to the device of :attr:`input`.\n",
      "    requires_grad (bool, optional): If autograd should record operations on the\n",
      "        returned tensor. Default: ``False``.\n",
      "    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n",
      "        returned Tensor. Default: ``torch.preserve_format``.\n",
      "\u001b[31mType:\u001b[39m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "torch.full_like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e6373",
   "metadata": {},
   "source": [
    "For additional details on both implementations, Sebastian refers to a [GitHub discussion](https://github.com/rasbt/LLMs-from-scratch/discussions/326)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d97619",
   "metadata": {},
   "source": [
    "### 3.3 Modifying The Text Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8ef872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying temperature scaling and top-k sampling to generate_simple() \n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # Addition: Filter logits with top_k sampling --Sebastian's original version\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "        \n",
    "        # Addition: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits  = logits / temperature\n",
    "            # Apply softmax \n",
    "            probs = torch.softmax(logits, dim=-1)  #(bs, context_len)\n",
    "            # Sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(bs, 1)\n",
    "        \n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True) #(bs, 1)\n",
    "        \n",
    "        if idx_next == eos_id: # Stop text generation if end_of_sequence token is encountered with eos_id\n",
    "            break\n",
    "        \n",
    "        # Sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (bs, num_tokens+1)\n",
    "    \n",
    "    return idx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbdb95d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Time and tide wait I felt it was dead I felt able to pictures--oh handsome, one\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Time and tide wait\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.45\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25068da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef5141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
