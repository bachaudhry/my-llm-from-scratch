{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4f2754",
   "metadata": {},
   "source": [
    "# **Pretraining an LLM on Unlabeled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543b63a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.1\n",
      "numpy version: 2.2.5\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights since earlier models were trained in TensorFlow\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbfa8a",
   "metadata": {},
   "source": [
    "This notebook covers the following topics in addition to covering a basic training loop for an introduction to model evaluations during LLM pretraining.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86298966",
   "metadata": {},
   "source": [
    "## **1. Evaluating Generative Text Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a74d0",
   "metadata": {},
   "source": [
    "Let's begin by setting up the LLM's configuration from previous notebooks. We will be retaining the original context length since we have access to a reasonable consumer grade GPU which should easily handle `context_length: 1024`. This is the same configuration as the original GPT-2 model with 124 million parameters.\n",
    "\n",
    "`text_to_token_ids()` and `token_ids_to_text()` are functions which facilitate the conversion between text and token representations. Additionally, it is important to note that modern LLMs **do not** use a dropout rate as well as bias vectors. The dropout rate below reflects the settings used to train the original GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.components import GPTModel\n",
    "\n",
    "# GPT configuration from previos NBs\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Retaining original context length\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate \n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # Dropout disabled during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c4077f",
   "metadata": {},
   "source": [
    "`NOTE` Experiment with context lengths and embedding dimensions to generate longer sequences from larger text files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01a17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " In the grim darkness of the far futurerotto defundFurthermore Levinealwaysï¿½ Cam vaguely unearthed\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from utils.components import generate_text_simple\n",
    "\n",
    "# Pipeline functions\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Removing batch dim\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"In the grim darkness of the far future\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11161b8",
   "metadata": {},
   "source": [
    "The generated text is gibberish since the model hasn't been trained yet. We will also be evaluating the quality of text generation in sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b4d05",
   "metadata": {},
   "source": [
    "### **1.1 Calculating The Text Generation Loss i.e. Cross-Entropy and Perplexity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd34b0",
   "metadata": {},
   "source": [
    "For demonstration purposes, we will create two inputs of three tokens each and will then compute vectors containing the probability scores corresponding to each token in the vocabulary. The index of the highest probability score in each vector represents the most likely next token ID which is then returned to generate the required text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffbc0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ddb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "    \n",
    "probs = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probs.shape) # Shape ==> (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d42e10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[24851],\n",
      "         [  406],\n",
      "         [40115]],\n",
      "\n",
      "        [[29716],\n",
      "         [40825],\n",
      "         [19647]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1d1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: etti L HO\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e053b",
   "metadata": {},
   "source": [
    "The output tokens don't match the target tokens we created above - as expected. But we also want to know how far the generated tokens are from the correct predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a35293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([4.3173e-06, 2.1993e-05, 1.0362e-05])\n",
      "Text 1: tensor([1.2699e-05, 2.9482e-05, 6.5255e-06])\n"
     ]
    }
   ],
   "source": [
    "# Token probabilities corresponding to the target indices\n",
    "text_idx = 0\n",
    "target_probs_1 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probs_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probs_2 = probs[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ae5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-12.3529, -10.7248, -11.4774, -11.2740, -10.4317, -11.9398])\n"
     ]
    }
   ],
   "source": [
    "# Compute log of all token probabilities\n",
    "log_probs = torch.log(torch.cat((target_probs_1, target_probs_2)))\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c144d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.3668)\n"
     ]
    }
   ],
   "source": [
    "# Computing the average log probability of each token\n",
    "avg_log_probs = torch.mean(log_probs)\n",
    "print(avg_log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ff640",
   "metadata": {},
   "source": [
    ">- The goal is to make this average log probability as large as possible by optimizing the model weights\n",
    ">- Due to the log, the largest possible value is 0, and we are currently far away from 0\n",
    ">- In deep learning, instead of maximizing the average log-probability, it's a standard convention to minimize the *negative* average log-probability value.\n",
    "\n",
    "**`CROSS ENTROPY`** This measures the difference between two probability distributions - which in this case are the true distributions of the labels and the predicted distributions from the model i.e. the token probabilities generated by the LLM. PyTorch uses the cross-entropy function for discrete outcomes which _is similar to negative average log probability of the target tokens given the model's generated token probabilities_, thus making the two terms interchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9799e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.3668)\n"
     ]
    }
   ],
   "source": [
    "# Minimize the negative average log-probability\n",
    "neg_avg_log_prob = avg_log_probs * -1\n",
    "print(neg_avg_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff311793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Prior to implementing cross entropy, we should check the shape of logits and targets\n",
    "# Logits shape --> (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce95555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "Cross-Entropy loss: tensor(11.3668)\n"
     ]
    }
   ],
   "source": [
    "# Flattening above tensors for cross entropy. Flattening is done by combining over the batch dimension\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "# Applying cross entropy loss\n",
    "# Previously we, applied the softmax function, selected probability scores corresponding to target ids and\n",
    "# computed the negative average log probabilities. Cross Entropy handles all of these steps.\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "\n",
    "# Printing shapes and cross entropy loss\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "print(\"Cross-Entropy loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3a0cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "torch.nn.functional.cross_entropy(\n",
      "    input: torch.Tensor,\n",
      "    target: torch.Tensor,\n",
      "    weight: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    size_average: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ignore_index: int = -\u001b[32m100\u001b[39m,\n",
      "    reduce: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    reduction: str = \u001b[33m'mean'\u001b[39m,\n",
      "    label_smoothing: float = \u001b[32m0.0\u001b[39m,\n",
      ") -> torch.Tensor\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Compute the cross entropy loss between input logits and target.\n",
      "\n",
      "See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
      "\n",
      "Args:\n",
      "    input (Tensor) : Predicted unnormalized logits;\n",
      "        see Shape section below for supported shapes.\n",
      "    target (Tensor) : Ground truth class indices or class probabilities;\n",
      "        see Shape section below for supported shapes.\n",
      "    weight (Tensor, optional): a manual rescaling weight given to each\n",
      "        class. If given, has to be a Tensor of size `C`\n",
      "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
      "        the losses are averaged over each loss element in the batch. Note that for\n",
      "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
      "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
      "        when reduce is ``False``. Default: ``True``\n",
      "    ignore_index (int, optional): Specifies a target value that is ignored\n",
      "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
      "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
      "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
      "        Default: -100\n",
      "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
      "        losses are averaged or summed over observations for each minibatch depending\n",
      "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
      "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
      "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
      "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
      "        ``'mean'``: the sum of the output will be divided by the number of\n",
      "        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
      "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
      "        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
      "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
      "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
      "        become a mixture of the original ground truth and a uniform distribution as described in\n",
      "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
      "\n",
      "Shape:\n",
      "    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
      "      in the case of `K`-dimensional loss.\n",
      "    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n",
      "      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n",
      "      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n",
      "\n",
      "    where:\n",
      "\n",
      "    .. math::\n",
      "        \\begin{aligned}\n",
      "            C ={} & \\text{number of classes} \\\\\n",
      "            N ={} & \\text{batch size} \\\\\n",
      "        \\end{aligned}\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> # Example of target with class indices\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
      "    >>> loss = F.cross_entropy(input, target)\n",
      "    >>> loss.backward()\n",
      "    >>>\n",
      "    >>> # Example of target with class probabilities\n",
      "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
      "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
      "    >>> loss = F.cross_entropy(input, target)\n",
      "    >>> loss.backward()\n",
      "\u001b[31mFile:\u001b[39m      ~/code/nbs/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/nn/functional.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557c90c",
   "metadata": {},
   "source": [
    "**`Perplexity`** This is a measure used in conjuction with cross entropy loss to evaluate the performance of models in tasks like language modeling. It can provide a more interpretable way to understand the uncertainty of a model in predicting the next sequence. Specifically, it measures how well the probability distribution predicted by the model matches the actual distribution of the words in the dataset. Lower perplexity indcates that the model predictions are closed to the actual distribution.\n",
    "\n",
    "This measure is often considered to be more interpretable than the raw loss value because it signifies the effective vocabulary size that the model is _unsure_ of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d70dc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(86402.1562)\n"
     ]
    }
   ],
   "source": [
    "# Calculating the perplexity \n",
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6110d4",
   "metadata": {},
   "source": [
    "### **1.2 Calculating Training and Validation Losses** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36c97b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Loading sample training text.\n",
    "#file_path = \"data/the-law-bastiat.txt\"\n",
    "file_path = \"data/the-verdict.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57b0673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no  \n",
      "\n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# First and last99 chars\n",
    "print(text_data[:99], \"\\n\")\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ea6491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters: \", total_characters)\n",
    "print(\"Tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37d7cc",
   "metadata": {},
   "source": [
    "Here, we will be training our model with training data presented in similarly sized chunks for simplicity and efficiency. In practice, it can also be beneficial to train an LLM with variable-length inputs to help it to better generalize across different types of inputs when it is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f534f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.components import create_dataloader_v1\n",
    "\n",
    "# Training / validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc5602c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running sanity check\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader!\")\n",
    "    \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d18ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Checking shapes of train and val loaders.\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8526bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# Checking token sizes\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "    \n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90df534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the loss of a single batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "# Calculate the loss over all batches sampled by a given data loader.\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce num of batches to match the total number of batches in the data loader\n",
    "        # in case values are exceeded.\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else: \n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8668e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.003963894314236\n",
      "Validation loss: 11.044095039367676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "    \n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031ffd2",
   "metadata": {},
   "source": [
    "## Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb7a6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            \n",
    "            # Additional eval step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        # Print sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context)\n",
    "        \n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "    \n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "        model.eval()\n",
    "        context_size = model.pos_emb.weight.shape[0]\n",
    "        encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "        with torch.no_grad():\n",
    "            token_ids = generate_text_simple(\n",
    "                model=model, idx=encoded,\n",
    "                max_new_tokens=50, context_size=context_size\n",
    "                )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "        model.train()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fe9a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1b5a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000): Train loss 10.032, Val loss 10.127\n",
      "Epoch 1 (Step 000005): Train loss 8.172, Val loss 8.353\n",
      "In the grim darkness of the far future,                                                 \n",
      "Epoch 2 (Step 000010): Train loss 6.796, Val loss 7.099\n",
      "Epoch 2 (Step 000015): Train loss 6.064, Val loss 6.640\n",
      "In the grim darkness of the far future, the, the, the, the, the, the, the, the, the, the, the                            \n",
      "Epoch 3 (Step 000020): Train loss 5.668, Val loss 6.606\n",
      "Epoch 3 (Step 000025): Train loss 5.292, Val loss 6.571\n",
      "In the grim darkness of the far future aburn had a he had aII. Gisburn had a I had a in theI had a him, and I had a it was a I had theI had theI. Gisburn had theI to see it was\n",
      "Epoch 4 (Step 000030): Train loss 5.211, Val loss 6.418\n",
      "Epoch 4 (Step 000035): Train loss 4.470, Val loss 6.382\n",
      "In the grim darkness of the far future--and I had a felt, and I had been                                       \n",
      "Epoch 5 (Step 000040): Train loss 3.923, Val loss 6.297\n",
      "In the grim darkness of the far future--I felt.                                              \n",
      "Epoch 6 (Step 000045): Train loss 3.522, Val loss 6.302\n",
      "Epoch 6 (Step 000050): Train loss 3.104, Val loss 6.257\n",
      "In the grim darkness of the far future that, and he was not the fact with the. \"Oh, and as a little, I had to see a smile behind his close the donkey, I had to have him, and.          \n",
      "Epoch 7 (Step 000055): Train loss 2.531, Val loss 6.275\n",
      "Epoch 7 (Step 000060): Train loss 2.008, Val loss 6.290\n",
      "In the grim darkness of the far future that, and he was not, and uncertain.  \"I had been by me--as I had the man of the picture--as Jack himself, with a picture was one of Jack's \"strongest,\" she was a, he said\n",
      "Epoch 8 (Step 000065): Train loss 1.626, Val loss 6.311\n",
      "Epoch 8 (Step 000070): Train loss 1.362, Val loss 6.319\n",
      "In the grim darkness of the far future that I felt able to the fact with a.  \"Once, and thought of the fact, I had been taken.  \"I turned, I had again run over the donkey.  \"I turned to see it would have\n",
      "Epoch 9 (Step 000075): Train loss 1.104, Val loss 6.297\n",
      "Epoch 9 (Step 000080): Train loss 0.746, Val loss 6.476\n",
      "In the grim darkness of the far future that, one of the deep arm-chairs forward. \"Once, I was, in the women had made him--it was fitting that they should mourn him. Gisburn had been the \"There were days when I had not look at\n",
      "Epoch 10 (Step 000085): Train loss 0.631, Val loss 6.576\n",
      "In the grim darkness of the far future that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. Gisburn drew back his glory, he had dropped his painting, had been the man of the hour. The younger artist was said\n",
      "Training completed in 0.22 mins.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"In the grim darkness of the far future\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time:.2f} mins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39b969a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    #plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae217a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
