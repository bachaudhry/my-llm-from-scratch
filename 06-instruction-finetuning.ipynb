{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a279df",
   "metadata": {},
   "source": [
    "# **Finetuning to Follow Instructions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a009fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version:2.2.5\n",
      "matplotlib version:3.10.1\n",
      "tiktoken version:0.9.0\n",
      "torch version:2.7.0\n",
      "tqdm version:4.67.1\n",
      "tensorflow version:2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       \n",
    "    \"matplotlib\", \n",
    "    \"tiktoken\",    \n",
    "    \"torch\",      \n",
    "    \"tqdm\",        \n",
    "    \"tensorflow\",\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version:{version(p)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2a456",
   "metadata": {},
   "source": [
    "## **1. Instruction Finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c99c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47314e07",
   "metadata": {},
   "source": [
    "## **2. Dataset Preparation for Supervised Finetuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532cb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, requests\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "            \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c9f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/instruct/instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\" \n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586ee0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bb6410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"Provide the past participle form of 'choose.'\", 'input': '', 'output': \"The past participle form of 'choose' is 'chosen.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[444])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222e204",
   "metadata": {},
   "source": [
    "- Items in the downloaded `data` list are stored as dictionaries.\n",
    "- Entries may contain empty `input` fields. \n",
    "- There are a number of ways to format the entries as inputs to the LLM; Two example formats that were used for training the Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) and Phi-3 (https://arxiv.org/abs/2404.14219) LLMs are illustrated below.\n",
    "    - Alpaca-style prompt formatting was the original prompt template for instruction fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7832282",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/04.webp?2\" width=640px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381c0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceeding with the Alpaca style prompt formatting.\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a reponse that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    \n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead8a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a reponse that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion \n",
      "\n",
      "#### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of a formatted response with input fields\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n#### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input, desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1590b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a reponse that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide the past participle form of 'choose.' \n",
      "\n",
      "#### Response:\n",
      "The past participle form of 'choose' is 'chosen.'\n"
     ]
    }
   ],
   "source": [
    "# Example where the input field is empty\n",
    "model_input = format_input(data[444])\n",
    "desired_response = f\"\\n\\n#### Response:\\n{data[444]['output']}\"\n",
    "\n",
    "print(model_input, desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cce718",
   "metadata": {},
   "source": [
    "- Diving the dataset into `training`, `validation` and `test` sets before passing them to the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3da2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = int(len(data) * 0.85)\n",
    "test_set = int(len(data) * 0.1)\n",
    "val_set = len(data) - train_set - test_set\n",
    "\n",
    "train_data = data[:train_set]\n",
    "test_data = data[train_set : train_set + test_set]\n",
    "val_data = data[train_set + test_set:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0030138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037ebe2",
   "metadata": {},
   "source": [
    "## **3. Organizing Data into Training Batches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0509d9b",
   "metadata": {},
   "source": [
    "Dataset batching can be summarized as in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e740472",
   "metadata": {},
   "source": [
    "- We tackle this dataset batching in several steps, as summarized in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/06.webp?1\" width=640px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228fea5",
   "metadata": {},
   "source": [
    "- We will implement an `InstructionDataset` class which pretokenizes all inputs in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408cad1",
   "metadata": {},
   "source": [
    "- First, we implement an `InstructionDataset` class that pre-tokenizes all inputs in the dataset, similar to the `SpamDataset` in chapter 6\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/07.webp?1\" width=640px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38baea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        \n",
    "        # Pre-tokenizing the text\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34acf66",
   "metadata": {},
   "source": [
    "- As before, all input batches will be padded to a similar length.\n",
    "- We will be using the `<|endoftext|>` token as a padding token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52360227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a20d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developing a custom collate function that can be passed to the dataloader.\n",
    "# Its purpose is to pad the training examples in each batch to have the same length\n",
    "# Note that different batches may vary in length.\n",
    "def collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1 to add an extra\n",
    "    # padding token.\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add the padding token\n",
    "        new_item += [pad_token_id] \n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # padded[:-1] allows us to remove the extra padded token\n",
    "        # which was added with +1 in batch_max_length. We will\n",
    "        # circle back to the extra padding token in later sections.\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    # Convert list of inputs to tensor and transfer to target device.\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98275955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5], [6, 7], [8, 9, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1 = [0, 1, 2, 3, 4, 5]\n",
    "inp_2 = [6, 7]\n",
    "inp_3 = [8, 9, 10]\n",
    "\n",
    "batch = (\n",
    "    inp_1,\n",
    "    inp_2,\n",
    "    inp_3\n",
    ")\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91581126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5],\n",
      "        [    6,     7, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9,    10, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "print(collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb728185",
   "metadata": {},
   "source": [
    "- The collate function above only handles inputs to an LLM. To allow training for instruction following, we will need the target values as well.\n",
    "- Similar to pretraining an LLM, targets will simply be inputs shifted by 1 position to the right to allow next-token predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b3afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the collate function\n",
    "\n",
    "def collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add padding token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1]) # Truncate last token for inputs\n",
    "        targets = torch.tensor(padded[1:]) # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f629c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5],\n",
      "        [    6,     7, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9,    10, 50256, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4,     5, 50256],\n",
      "        [    7, 50256, 50256, 50256, 50256, 50256],\n",
      "        [    9,    10, 50256, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0277fed",
   "metadata": {},
   "source": [
    "- Introducing an `ignore_index` value to replace all padding token IDs with a new value. This new value will be ignored during loss calculations.\n",
    "- In this case, we will be replacing `50256` with `-100`.\n",
    "- We will also introduce `allowed_max_length` in case we want to limit the length of the samples. \n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/11.webp?1\" width=640px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0d44a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a29fda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # Replace all except the first padding tokens in targets using ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "            \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf6c3400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5],\n",
      "        [    6,     7, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9,    10, 50256, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4,     5, 50256],\n",
      "        [    7, 50256,  -100,  -100,  -100,  -100],\n",
      "        [    9,    10, 50256,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd648c1",
   "metadata": {},
   "source": [
    "### 3.1 The Role of `-100` in Ignoring Padding Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699abbaf",
   "metadata": {},
   "source": [
    "- Assuming a trivial classification task with 2 class labels, 0 and 1.\n",
    "- Calculating the loss based on the logit values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "689dcafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a291d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "369a09fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3:  tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Replacing the class label of one of the examples with -100\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3: \", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e2b17",
   "metadata": {},
   "source": [
    "- This shows that cross-entropy loss function ignored the training example with `-100` label.\n",
    "- PyTorch, by default, has the `cross_entropy(..., ignore_index=-100)` setting to ignore examples corresponding to the -100 label.\n",
    "- This allows us to ignore the end-of-text / padding tokens in the training batches.\n",
    "- Do note that we **don't** want to ignore the first instance of the end-of-text padding token (50256) because it serves as a signal to the LLM that the reponse is complete.\n",
    "- Target token IDs, which correspond to instructions, are commonly masked out as well.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/13.webp\" width=640px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f457e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
