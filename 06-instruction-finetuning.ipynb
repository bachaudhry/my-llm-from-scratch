{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a279df",
   "metadata": {},
   "source": [
    "# **Finetuning to Follow Instructions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a009fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version:2.2.5\n",
      "matplotlib version:3.10.1\n",
      "tiktoken version:0.9.0\n",
      "torch version:2.7.0\n",
      "tqdm version:4.67.1\n",
      "tensorflow version:2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       \n",
    "    \"matplotlib\", \n",
    "    \"tiktoken\",    \n",
    "    \"torch\",      \n",
    "    \"tqdm\",        \n",
    "    \"tensorflow\",\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version:{version(p)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2a456",
   "metadata": {},
   "source": [
    "## **1. Instruction Finetuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c99c0",
   "metadata": {},
   "source": [
    "Add Prose..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47314e07",
   "metadata": {},
   "source": [
    "## **2. Dataset Preparation for Supervised Finetuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532cb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, requests\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "            \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c9f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries 1100\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/instruct/instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\" \n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586ee0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05bb6410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"Provide the past participle form of 'choose.'\", 'input': '', 'output': \"The past participle form of 'choose' is 'chosen.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[444])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222e204",
   "metadata": {},
   "source": [
    "- Items in the downloaded `data` list are stored as dictionaries.\n",
    "- Entries may contain empty `input` fields. \n",
    "- There are a number of ways to format the entries as inputs to the LLM; Two example formats that were used for training the Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) and Phi-3 (https://arxiv.org/abs/2404.14219) LLMs are illustrated below.\n",
    "    - Alpaca-style prompt formatting was the original prompt template for instruction fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7832282",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/04.webp?2\" width=640px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381c0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceeding with the Alpaca style prompt formatting.\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a reponse that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    \n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead8a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a reponse that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion \n",
      "\n",
      "#### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of a formatted response with input fields\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n#### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input, desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1590b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a reponse that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide the past participle form of 'choose.' \n",
      "\n",
      "#### Response:\n",
      "The past participle form of 'choose' is 'chosen.'\n"
     ]
    }
   ],
   "source": [
    "# Example where the input field is empty\n",
    "model_input = format_input(data[444])\n",
    "desired_response = f\"\\n\\n#### Response:\\n{data[444]['output']}\"\n",
    "\n",
    "print(model_input, desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cce718",
   "metadata": {},
   "source": [
    "- Diving the dataset into `training`, `validation` and `test` sets before passing them to the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3da2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = int(len(data) * 0.85)\n",
    "test_set = int(len(data) * 0.1)\n",
    "val_set = len(data) - train_set - test_set\n",
    "\n",
    "train_data = data[:train_set]\n",
    "test_data = data[train_set : train_set + test_set]\n",
    "val_data = data[train_set + test_set:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0030138e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037ebe2",
   "metadata": {},
   "source": [
    "## **3. Organizing Data into Training Batches**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0509d9b",
   "metadata": {},
   "source": [
    "Dataset batching is summarized in the figure below..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e740472",
   "metadata": {},
   "source": [
    "- We tackle this dataset batching in several steps, as summarized in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/06.webp?1\" width=640px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228fea5",
   "metadata": {},
   "source": [
    "- We will implement an `InstructionDataset` class which pretokenizes all inputs in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408cad1",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/07.webp?1\" width=640px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38baea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        \n",
    "        # Pre-tokenizing the text\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34acf66",
   "metadata": {},
   "source": [
    "- As before, all input batches will be padded to a similar length.\n",
    "- We will be using the `<|endoftext|>` token as a padding token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52360227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a20d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developing a custom collate function that can be passed to the dataloader.\n",
    "# Its purpose is to pad the training examples in each batch to have the same length\n",
    "# Note that different batches may vary in length.\n",
    "def collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1 to add an extra\n",
    "    # padding token.\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add the padding token\n",
    "        new_item += [pad_token_id] \n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * \n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # padded[:-1] allows us to remove the extra padded token\n",
    "        # which was added with +1 in batch_max_length. We will\n",
    "        # circle back to the extra padding token in later sections.\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    \n",
    "    # Convert list of inputs to tensor and transfer to target device.\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98275955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5], [6, 7], [8, 9, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_1 = [0, 1, 2, 3, 4, 5]\n",
    "inp_2 = [6, 7]\n",
    "inp_3 = [8, 9, 10]\n",
    "\n",
    "batch = (\n",
    "    inp_1,\n",
    "    inp_2,\n",
    "    inp_3\n",
    ")\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91581126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5],\n",
      "        [    6,     7, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9,    10, 50256, 50256, 50256]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb728185",
   "metadata": {},
   "source": [
    "- The collate function above only handles inputs to an LLM. To allow training for instruction following, we will need the target values as well.\n",
    "- Similar to pretraining an LLM, targets will simply be inputs shifted by 1 position to the right to allow next-token predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b3afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the collate function\n",
    "\n",
    "def collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    \n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add padding token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1]) # Truncate last token for inputs\n",
    "        targets = torch.tensor(padded[1:]) # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "        \n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f629c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5],\n",
      "        [    6,     7, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9,    10, 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4,     5, 50256],\n",
      "        [    7, 50256, 50256, 50256, 50256, 50256],\n",
      "        [    9,    10, 50256, 50256, 50256, 50256]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0277fed",
   "metadata": {},
   "source": [
    "- Introducing an `ignore_index` value to replace all padding token IDs with a new value. This new value will be ignored during loss calculations.\n",
    "- In this case, we will be replacing `50256` with `-100`.\n",
    "- We will also introduce `allowed_max_length` in case we want to limit the length of the samples. \n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/11.webp?1\" width=640px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0d44a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a29fda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        \n",
    "        # Replace all except the first padding tokens in targets using ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "            \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    \n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    \n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf6c3400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4,     5],\n",
      "        [    6,     7, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9,    10, 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4,     5, 50256],\n",
      "        [    7, 50256,  -100,  -100,  -100,  -100],\n",
      "        [    9,    10, 50256,  -100,  -100,  -100]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd648c1",
   "metadata": {},
   "source": [
    "### 3.1 The Role of `-100` in Ignoring Padding Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699abbaf",
   "metadata": {},
   "source": [
    "- Assuming a trivial classification task with 2 class labels, 0 and 1.\n",
    "- Calculating the loss based on the logit values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "689dcafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a291d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "369a09fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3:  tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Replacing the class label of one of the examples with -100\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3: \", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e2b17",
   "metadata": {},
   "source": [
    "- This shows that cross-entropy loss function ignored the training example with `-100` label.\n",
    "- PyTorch, by default, has the `cross_entropy(..., ignore_index=-100)` setting to ignore examples corresponding to the -100 label.\n",
    "- This allows us to ignore the end-of-text / padding tokens in the training batches.\n",
    "- Do note that we **don't** want to ignore the first instance of the end-of-text padding token (50256) because it serves as a signal to the LLM that the reponse is complete.\n",
    "- Target token IDs, which correspond to instructions, are commonly masked out as well.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/13.webp\" width=640px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b5821",
   "metadata": {},
   "source": [
    "## **4. Creating DataLoaders for the Instruction Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596d4fb",
   "metadata": {},
   "source": [
    "- `collate_fn` allows us to move the data to the `gpu` directly, thereby bypassing the main the training loop for added efficiency.\n",
    "- The `partial` function will be used to create a new function with a pre-filled `device` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f457e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ef3e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef3bde",
   "metadata": {},
   "source": [
    "- `collate_fn` will be used in the batching process once the dataloaders are instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b9fe992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45a6b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15874b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n"
     ]
    }
   ],
   "source": [
    "# Viewing dimensions of the resulting input and target batches\n",
    "print(\"Train Loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db978119",
   "metadata": {},
   "source": [
    "- All batches have a batch size of 8, but varying lengths. We will also double check that the inputs contain `<|endoftext|>` padding tokens corresponding to token ID `50256`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cb74616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  1128,  2591,   326, 20431, 32543,   262,  2581,    13,   198,\n",
      "          198, 21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,\n",
      "          257,   985,   576,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "          464,  5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,\n",
      "           25,   198,   464,  5156,   318,   355, 13779,   355,   257,  4936,\n",
      "           13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0') \n",
      " 8\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0], \"\\n\", len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98094bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         1128,  2591,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c15104",
   "metadata": {},
   "source": [
    "## **5. Loading a Pre-trained LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb2c7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.components import GPTModel\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb0da2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"gpt2/gpt2-medium-355M.pth\"\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "model.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "model.eval();\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f41f072",
   "metadata": {},
   "source": [
    "- Testing the model on a validation task before finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69de9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a reponse that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a86e22b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 14:57:35.634302: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-04 14:57:35.640287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762250255.647106  106168 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762250255.649123  106168 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762250255.654267  106168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762250255.654274  106168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762250255.654275  106168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762250255.654276  106168 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-04 14:57:35.656219: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from utils.gpt_generate import generate\n",
    "from utils.gpt_generate import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c511d6",
   "metadata": {},
   "source": [
    "- Compared to previous NBs, where the `generate` function returned both input and output text, we will now need to isolate the response by subtracting the length of the instruction from the start of the `generated_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4980fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Example:\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Example:\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Reponse:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5d800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
